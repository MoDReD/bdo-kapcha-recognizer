{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/symbios/work/deep_learning/kapcha/data/store'\n",
    "\n",
    "def save_im(conv, name):\n",
    "    final = torch.cat((conv.data), 0)\n",
    "    print(name, '  ', conv.size(), '   ', final.size())\n",
    "    plt.imsave(fname=name, arr=final, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KapchaDataset(Dataset):\n",
    "    \"\"\"Kapcha dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, root_dir, img_dir, csv_dir, length, first_idx=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Root directory.\n",
    "            img_dir  (string): Directory with all images.\n",
    "            csv_dir  (string): Directory with labels.\n",
    "            length      (int): Total length of dataset.\n",
    "            first_idx   (int): First data index.\n",
    "        \"\"\"\n",
    "        self.root_dir   = root_dir\n",
    "        self.img_dir    = os.path.join(root_dir, img_dir)\n",
    "        self.csv_dir    = os.path.join(root_dir, csv_dir)\n",
    "        self.first_idx  = first_idx\n",
    "        self.length     = length\n",
    "#         self.mean       = (0.079210128784179684, 0.079210128784179684, 0.079210128784179684)\n",
    "#         self.std        = (0.083445704142252608, 0.083445704142252608, 0.083445704142252608)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx = self.first_idx + idx\n",
    "\n",
    "        img_name    = os.path.join(self.img_dir, '{0}.jpg'.format(idx))\n",
    "        image       = Image.open(img_name)\n",
    "        image       = np.array(image).astype('float32') / 255\n",
    "        \n",
    "        image       = image[:, :, 0].reshape(1, 58, 372)\n",
    "        image       = torch.from_numpy(image)\n",
    "\n",
    "        label_name  = os.path.join(self.csv_dir, '{0}.csv'.format(idx))\n",
    "        labels      = np.genfromtxt(label_name, delimiter=',').astype('int64')\n",
    "        labels      = torch.from_numpy(labels)\n",
    "\n",
    "        sample = {'image': image, 'labels': labels, 'idx': idx}\n",
    "\n",
    "        return sample\n",
    "\n",
    "train_dataset   = KapchaDataset(root_dir=data_dir,\n",
    "                                img_dir='kapcha',\n",
    "                                csv_dir='order',\n",
    "                                length=12000,\n",
    "                                first_idx=0)\n",
    "\n",
    "train_dataset   = DataLoader(train_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             num_workers=0)\n",
    "\n",
    "test_dataset    = KapchaDataset(root_dir=data_dir,\n",
    "                                img_dir='kapcha',\n",
    "                                csv_dir='order',\n",
    "                                length=2369,\n",
    "                                first_idx=12000)\n",
    "\n",
    "test_dataset    = DataLoader(test_dataset,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Parser, self).__init__()\n",
    "        self.pool = torch.nn.MaxPool2d(2, stride=2)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.conv1 = torch.nn.Conv2d(1, 16, 3)\n",
    "        self.conv2 = torch.nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = torch.nn.Conv2d(32, 64, 3)\n",
    "        \n",
    "        self.linear1 = torch.nn.Linear(64 * 5 * 44, 1000)\n",
    "        self.linear2 = torch.nn.Linear(1000, 100)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        conv1 = self.conv1(inputs)\n",
    "        relu1 = self.relu(conv1)\n",
    "        pool1 = self.pool(relu1)\n",
    "        \n",
    "        conv2 = self.conv2(pool1)\n",
    "        relu2 = self.relu(conv2)\n",
    "        pool2 = self.pool(relu2)\n",
    "        \n",
    "        conv3 = self.conv3(pool2)\n",
    "        relu3 = self.relu(conv3)\n",
    "        pool3 = self.pool(relu3)\n",
    "        \n",
    "        re_pool3 = pool3.view(-1 , 64 * 5 * 44)\n",
    "#         linear1 = torch.zeros(1,1)\n",
    "#         linear2 = torch.zeros(1,1)\n",
    "        \n",
    "        linear1 = self.linear1(pool3)\n",
    "#         linear2 = torch.zeros(1,1)\n",
    "        \n",
    "        return {'1_conv1': conv1, '2_relu1': relu1, '3_pool1': pool1,\n",
    "                '4_conv2': conv2, '5_relu2': relu2, '6_pool2': pool2,\n",
    "                '7_conv3': conv3, '8_relu3': relu3, '9_pool3': pool3,\n",
    "                '10_linear1': linear1, '11_linear2': linear2}\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parser(\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
       "  (relu): LeakyReLU(0.01)\n",
       "  (sigmoid): Sigmoid()\n",
       "  (conv1): Conv2d (1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d (16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d (32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (linear1): Linear(in_features=14080, out_features=1000)\n",
       "  (linear2): Linear(in_features=1000, out_features=100)\n",
       ")"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Parser().cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2_relu1 torch.Size([10, 16, 56, 370])\n",
      "4_conv2 torch.Size([10, 32, 26, 183])\n",
      "10_linear1 torch.Size([1, 1])\n",
      "5_relu2 torch.Size([10, 32, 26, 183])\n",
      "6_pool2 torch.Size([10, 32, 13, 91])\n",
      "1_conv1 torch.Size([10, 16, 56, 370])\n",
      "3_pool1 torch.Size([10, 16, 28, 185])\n",
      "9_pool3 torch.Size([10, 64, 5, 44])\n",
      "11_linear2 torch.Size([1, 1])\n",
      "8_relu3 torch.Size([10, 64, 11, 89])\n",
      "7_conv3 torch.Size([10, 64, 11, 89])\n"
     ]
    }
   ],
   "source": [
    "data = it.next()\n",
    "inputs = Variable(data['image'].cuda())\n",
    "labels = Variable(data['labels'].cuda())\n",
    "\n",
    "layers = model(inputs)\n",
    "\n",
    "for i, key in enumerate(layers):\n",
    "    print(key, layers[key].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./parse_layers/2_relu1.png    torch.Size([16, 56, 370])     torch.Size([896, 370])\n",
      "./parse_layers/4_conv2.png    torch.Size([32, 26, 183])     torch.Size([832, 183])\n",
      "./parse_layers/5_relu2.png    torch.Size([32, 26, 183])     torch.Size([832, 183])\n",
      "./parse_layers/6_pool2.png    torch.Size([32, 13, 91])     torch.Size([416, 91])\n",
      "./parse_layers/1_conv1.png    torch.Size([16, 56, 370])     torch.Size([896, 370])\n",
      "./parse_layers/3_pool1.png    torch.Size([16, 28, 185])     torch.Size([448, 185])\n",
      "./parse_layers/9_pool3.png    torch.Size([64, 5, 44])     torch.Size([320, 44])\n",
      "./parse_layers/8_relu3.png    torch.Size([64, 11, 89])     torch.Size([704, 89])\n",
      "./parse_layers/7_conv3.png    torch.Size([64, 11, 89])     torch.Size([704, 89])\n"
     ]
    }
   ],
   "source": [
    "idn = 0\n",
    "\n",
    "value = it.next()\n",
    "value = Variable(value['image'].cuda())\n",
    "\n",
    "value.data.resize_(batch_size,1, 58, 372)\n",
    "\n",
    "pred = model(value)\n",
    "\n",
    "for i, key in enumerate(pred):\n",
    "    save_im(pred[key][idn], './parse_layers/{1}.png'.format(i,key))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
